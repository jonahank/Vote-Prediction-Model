{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scraper_functions as func\n",
    "import reshaping_functions as shape\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting the links for the vote pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_page = \"https://www.ft.dk/dokumenter/dokumentlister/afstemninger?startDate=20020201&endDate=20220315&pageSize=200&totalNumberOfRecords=8967\"\n",
    "current_page = func.get_soup_page(first_page)\n",
    "next_page = True\n",
    "vote_page_links = []\n",
    "pages_viewed = 0\n",
    "\n",
    "while next_page == True:\n",
    "    vote_links = func.get_vote_links(current_page)\n",
    "    links_set = set(vote_links)\n",
    "    vote_links = [val for val in links_set]\n",
    "    vote_links.sort(reverse=True)\n",
    "    \n",
    "    #saving the link pages.\n",
    "    vote_page_links += [val for val in links_set]\n",
    "    \n",
    "    if func.exists_next_page:\n",
    "        current_page = func.get_next_page(current_page)\n",
    "        pages_viewed += 1\n",
    "        if pages_viewed % 10 == 0: \n",
    "            print(pages_viewed, end=\"\")\n",
    "    else: \n",
    "        next_page = False\n",
    "        print(\"Finoto!\")\n",
    "\n",
    "    \n",
    "    #process_bar\n",
    "    print(\"|\", end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "if save == True:\n",
    "    with open(\"vote_pages_links.json\", \"w\") as fp:\n",
    "        json.dump(vote_page_links, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vote pages fetched: 8931\n"
     ]
    }
   ],
   "source": [
    "with open(\"vote_pages_links.json\", \"r\") as fp:\n",
    "    vp = json.load(fp)\n",
    "\n",
    "print(\"Vote pages fetched:\", len(vp))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'vote_id': [], 'description':[], 'votes':[], \n",
    "        'votes_by_party':[], 'vote_caller':[], 'url':[]}\n",
    "pages_processed = 0\n",
    "\n",
    "for i in range(len(vp)):\n",
    "    \n",
    "    try:\n",
    "        url = vp[i]\n",
    "        vote_page = func.get_soup_page(url)\n",
    "        \n",
    "        #id\n",
    "        vote_id = func.get_vote_id(vote_page)\n",
    "        \n",
    "        try:\n",
    "            description_page = func.get_description_page(vote_page)\n",
    "            description = func.get_vote_info(description_page)\n",
    "        except:\n",
    "            description = \"no description\"\n",
    "            \n",
    "        #votes by politician\n",
    "        votes = func.get_votes(vote_page)\n",
    "        \n",
    "        try:\n",
    "            vote_caller = func.get_vote_caller(description_page)\n",
    "        except:\n",
    "            vote_caller = None\n",
    "            \n",
    "        #votes aggregated by party\n",
    "        votes_by_party = func.get_votes_by_party(vote_page)    \n",
    "        \n",
    "        dict['vote_id'].append(vote_id)\n",
    "        dict['description'].append(description)\n",
    "        dict['votes_by_party'].append(votes_by_party)\n",
    "        dict['vote_caller'].append(vote_caller)\n",
    "        dict['votes'].append(votes)\n",
    "        dict['url'].append(url)\n",
    "        \n",
    "        #process_bar\n",
    "        pages_processed += 1\n",
    "        print(\"|\", end=\"\")\n",
    "        if pages_processed % 50 == 0: print(pages_processed)\n",
    "        #if pages_processed == 10: break\n",
    "        \n",
    "    except:\n",
    "        dict['vote_id'].append(\"no data\")\n",
    "        dict['description'].append(\"no data\")\n",
    "        dict['votes_by_party'].append(\"no data\")\n",
    "        dict['vote_caller'].append(\"no data\")\n",
    "        dict['votes'].append(\"note data\")\n",
    "        dict['url'].append(url)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(dict)\n",
    "# df.to_pickle(\"votes_scraped_over_night2.pkl\")\n",
    "# df.to_csv(\"votes_scraped_over_night2.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"votes_scraped_over_night.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows missing the description for the vote: 229\n",
      "number of rows missing data altogether for dataset: 22\n",
      "https://www.ft.dk//samling/20211/afstemning/55.htm\n",
      "https://www.ft.dk//samling/20201/afstemning/703.htm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vote_id</th>\n",
       "      <th>description</th>\n",
       "      <th>votes</th>\n",
       "      <th>votes_by_party</th>\n",
       "      <th>vote_caller</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6139</th>\n",
       "      <td>Afstemning nr. 373, 2009-10</td>\n",
       "      <td>[Fremsat:, 25-05-2010, Forslag til vedtagelse:...</td>\n",
       "      <td>{'politician': ['Anders Samuelsen', 'Anita Chr...</td>\n",
       "      <td>{'parties': ['Venstre (V)', 'Socialdemokratiet...</td>\n",
       "      <td>[Hanne Agersnap (udpeget af SF) (SF), Jørgen S...</td>\n",
       "      <td>https://www.ft.dk//samling/20091/afstemning/37...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          vote_id  \\\n",
       "6139  Afstemning nr. 373, 2009-10   \n",
       "\n",
       "                                            description  \\\n",
       "6139  [Fremsat:, 25-05-2010, Forslag til vedtagelse:...   \n",
       "\n",
       "                                                  votes  \\\n",
       "6139  {'politician': ['Anders Samuelsen', 'Anita Chr...   \n",
       "\n",
       "                                         votes_by_party  \\\n",
       "6139  {'parties': ['Venstre (V)', 'Socialdemokratiet...   \n",
       "\n",
       "                                            vote_caller  \\\n",
       "6139  [Hanne Agersnap (udpeget af SF) (SF), Jørgen S...   \n",
       "\n",
       "                                                    url  \n",
       "6139  https://www.ft.dk//samling/20091/afstemning/37...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of rows missing the description for the vote:\", len(df[df.description == 'no description']))\n",
    "print(\"number of rows missing data altogether for dataset:\", len(df[df.vote_id == \"no data\"]))\n",
    "\n",
    "print(df[df.vote_id == \"no data\"]['url'][359])\n",
    "print(vp[360])\n",
    "df[df.vote_id == \"no data\"]\n",
    "\n",
    "\n",
    "df[df.url.duplicated() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_urls = []\n",
    "\n",
    "for url in df[df['description'] == \"no data\"]['url']:\n",
    "    missing_urls.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||||||||||||||||||||"
     ]
    }
   ],
   "source": [
    "dict = {'vote_id': [], 'description':[], 'votes':[], \n",
    "        'votes_by_party':[], 'vote_caller':[], 'url':[]}\n",
    "pages_processed = 0\n",
    "\n",
    "for i in range(len(missing_urls)):\n",
    "    \n",
    "    try:\n",
    "        url = missing_urls[i]\n",
    "        vote_page = func.get_soup_page(url)\n",
    "        \n",
    "        #id\n",
    "        vote_id = func.get_vote_id(vote_page)\n",
    "        \n",
    "        try:\n",
    "            description_page = func.get_description_page(vote_page)\n",
    "            description = func.get_vote_info(description_page)\n",
    "        except:\n",
    "            description = \"no description\"\n",
    "            \n",
    "        #votes by politician\n",
    "        votes = func.get_votes(vote_page)\n",
    "        \n",
    "        try:\n",
    "            vote_caller = func.get_vote_caller(description_page)\n",
    "        except:\n",
    "            vote_caller = None\n",
    "            \n",
    "        #votes aggregated by party\n",
    "        votes_by_party = func.get_votes_by_party(vote_page)    \n",
    "        \n",
    "        dict['vote_id'].append(vote_id)\n",
    "        dict['description'].append(description)\n",
    "        dict['votes_by_party'].append(votes_by_party)\n",
    "        dict['vote_caller'].append(vote_caller)\n",
    "        dict['votes'].append(votes)\n",
    "        dict['url'].append(url)\n",
    "        \n",
    "        #process_bar\n",
    "        pages_processed += 1\n",
    "        print(\"|\", end=\"\")\n",
    "        if pages_processed % 50 == 0: print(pages_processed)\n",
    "        #if pages_processed == 10: break\n",
    "        \n",
    "    except:\n",
    "        dict['vote_id'].append(None)\n",
    "        dict['description'].append(None)\n",
    "        dict['votes_by_party'].append(None)\n",
    "        dict['vote_caller'].append(None)\n",
    "        dict['votes'].append(None)\n",
    "        dict['url'].append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=df[df['vote_id']=='no data'].index, inplace=True)\n",
    "\n",
    "df_missing_entries = pd.DataFrame(dict)\n",
    "df.append(df_missing_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"votes_scraped_over_night_v2.pkl\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "36e2581dfb10b7e3de3547be529c2e8e9e4d59798f578734b808d68ebdb931d0"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
