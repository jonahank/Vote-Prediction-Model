{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Socialdemokratiet',\n",
       " 'Venstre',\n",
       " 'Socialistisk Folkeparti',\n",
       " 'Det Radikale Venstre',\n",
       " 'Enhedslisten',\n",
       " 'Det Konservative Folkeparti',\n",
       " 'Dansk Folkeparti',\n",
       " 'Liberal Alliance',\n",
       " 'Alternativet']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./party_lst.json') as json_file:\n",
    "    parties = json.load(json_file)\n",
    "parties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow for each party"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "party = \"Alternativet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Absent</th>\n",
       "      <th>Against</th>\n",
       "      <th>For</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>parties</th>\n",
       "      <th>description</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Alternativet (ALT)</td>\n",
       "      <td>Regeringen (Socialdemokratiet), Radikale Venst...</td>\n",
       "      <td>2021-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Alternativet (ALT)</td>\n",
       "      <td>Forslaget har til formål at gennemføre en lang...</td>\n",
       "      <td>2018-05-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Absent  Against  For  Neutral             parties  \\\n",
       "0           9       1        0    0        0  Alternativet (ALT)   \n",
       "1           5       4        0    6        0  Alternativet (ALT)   \n",
       "\n",
       "                                         description        date  \n",
       "0  Regeringen (Socialdemokratiet), Radikale Venst...  2021-02-13  \n",
       "1  Forslaget har til formål at gennemføre en lang...  2018-05-15  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"./by_party_train/\" + party + \".csv\")\n",
    "df_test = pd.read_csv(\"./by_party_test/\" + party + \".csv\")\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_vote(df):\n",
    "  \n",
    "  df['label'] = df.apply(lambda x: 1 if x['Neutral']<x['Against']>x['For'] else 0 if x['Neutral']<x['For']>x['Against'] else None, axis=1)\n",
    "\n",
    "  df.rename(columns={'description':'text'}, inplace=True)\n",
    "  df = df[['text', 'label']]\n",
    "  df = df.dropna()\n",
    "  df['label'] = df.apply(lambda x: int(x['label']), axis=1)\n",
    "\n",
    "  return df\n",
    "\n",
    "## Note \"Against\" = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = preprocess_vote(df_train)\n",
    "df_test = preprocess_vote(df_test)\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = Dataset.from_pandas(df_train, preserve_index=True)\n",
    "test_set = Dataset.from_pandas(df_test, preserve_index=True)\n",
    "dataset = DatasetDict({'train':train_set,\n",
    "                        'test':test_set})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Models\n",
    "klimaBERT = \"/klimaBERTe4_v2.1\"\n",
    "checkpoint = klimaBERT\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    tokenized_batch = tokenizer(batch['text'], padding=True, truncation=True, max_length=512)\n",
    "    return tokenized_batch\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize, batched=True)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Steps for processing data\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
    "\n",
    "## Rename label column to labels, if not already done\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets.column_names\n",
    "## Our model needs columns that it already knows (the 4 below, NOT any custom columns like \"text\"):\n",
    "#['labels', 'input_ids', 'token_type_ids', 'attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "from datasets import load_metric\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    roc_auc = roc_auc_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'roc_auc_score': roc_auc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "training_args = TrainingArguments(\"test-trainer\", evaluation_strategy=\"epoch\", per_device_train_batch_size=2, num_train_epochs=5, seed=2022, save_strategy=\"no\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2) #Change num  of labels if needed\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set to use GPU\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"models_binary_party/\"+party)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a roc curve for a predictive model\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from matplotlib import pyplot\n",
    "from sklearn.dummy import DummyClassifier\n",
    "m = torch.nn.Softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weight_pred = trainer.predict(tokenized_datasets[\"test\"])[0]\n",
    "weight_for = []\n",
    "weight_against = []\n",
    "for input in weight_pred:\n",
    "    input2 = torch.from_numpy(input)\n",
    "    (i,k) = m(input2) #i=against, k=for\n",
    "    weight_for.append(i.item())\n",
    "    weight_against.append(k.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ROC CURVE\n",
    "testy = tokenized_datasets[\"test\"][\"labels\"]\n",
    "\n",
    "# plot no skill roc curve\n",
    "model = DummyClassifier(strategy='stratified')\n",
    "model.fit(tokenized_datasets[\"train\"], tokenized_datasets[\"train\"][\"labels\"])\n",
    "yhat = model.predict_proba(tokenized_datasets[\"test\"])\n",
    "pos_probs = yhat[:, 1]\n",
    "roc_auc_noskill = roc_auc_score(testy, pos_probs)\n",
    "\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--', label='No Skill')\n",
    "\n",
    "# plot the skill curve\n",
    "# retrieve just the probabilities for the positive class\n",
    "pos_probs = weight_against\n",
    "# calculate roc curve for model\n",
    "fpr, tpr, _ = roc_curve(testy, pos_probs)\n",
    "\n",
    "# plot model roc curve\n",
    "pyplot.plot(fpr, tpr, marker='.', label=f'Baseline-{party}')\n",
    "\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "roc_auc = roc_auc_score(testy, pos_probs)\n",
    "print('No Skill ROC AUC %.3f' % roc_auc_noskill)\n",
    "print('Baseline ROC AUC %.3f' % roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PR Curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "y = tokenized_datasets[\"test\"]\n",
    "no_of_pos = y[\"labels\"].sum().item()\n",
    "\n",
    "\n",
    "# calculate the no skill line as the proportion of the positive class\n",
    "no_skill = (no_of_pos / len(y))\n",
    "# plot the no skill precision-recall curve\n",
    "model = DummyClassifier(strategy='stratified')\n",
    "model.fit(tokenized_datasets[\"train\"], tokenized_datasets[\"train\"][\"labels\"])\n",
    "yhat = model.predict_proba(tokenized_datasets[\"test\"])\n",
    "pos_probs = yhat[:, 1]\n",
    "# calculate the precision-recall auc\n",
    "precision, recall, _ = precision_recall_curve(testy, pos_probs)\n",
    "auc_score_noskill = auc(recall, precision)\n",
    "pyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "\n",
    "# calculate model precision-recall curve\n",
    "pos_probs = weight_against\n",
    "precision, recall, _ = precision_recall_curve(testy, pos_probs)\n",
    "# plot the model precision-recall curve\n",
    "pyplot.plot(recall, precision, marker='.', label=f'Baseline-{party}')\n",
    "# axis labels\n",
    "pyplot.xlabel('Recall')\n",
    "pyplot.ylabel('Precision')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "auc_score = auc(recall, precision)\n",
    "print('No Skill PR AUC: %.3f' % auc_score_noskill)\n",
    "print('Logistic PR AUC: %.3f' % auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop for all parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for party in parties:\n",
    "    df_train = pd.read_csv(\"./by_party_train\" + party + \".csv\")\n",
    "    df_test = pd.read_csv(\"./by_party_test\" + party + \".csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For all (macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290893\n",
      "20423\n",
      "12978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\COBOD\\AppData\\Local\\Temp/ipykernel_12036/1141518180.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_c[\"year\"] = df_c[\"date\"].astype(\"str\").str[:4]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(\"../../climate_classifier/scored_data/votes_data_all_expanded_politician.pkl\")\n",
    "df = df.sample(frac=0.3)\n",
    "print(len(df))\n",
    "df_c = df[df[\"y_pred\"]==\"climate\"]\n",
    "print(len(df_c))\n",
    "df_c[\"year\"] = df_c[\"date\"].astype(\"str\").str[:4]\n",
    "df_c = df_c[df_c[\"year\"].astype(\"int\")>=2012]\n",
    "df_c.head(1)\n",
    "print(len(df_c))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>For</th>\n",
       "      <th>Absent</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Against</th>\n",
       "      <th>description</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>De danske ressourcer af olie og gas skal udnyt...</td>\n",
       "      <td>2012-02-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>De danske ressourcer af olie og gas skal udnyt...</td>\n",
       "      <td>2012-02-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     For  Absent  Neutral  Against  \\\n",
       "10     1       0        0        0   \n",
       "154    1       0        0        0   \n",
       "\n",
       "                                           description        date  \n",
       "10   De danske ressourcer af olie og gas skal udnyt...  2012-02-23  \n",
       "154  De danske ressourcer af olie og gas skal udnyt...  2012-02-23  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c[[\"For\", \"Absent\", \"Neutral\", \"Against\"]] = pd.get_dummies(df_c[\"vote\"])\n",
    "df_c = df_c[[\"For\", \"Absent\", \"Neutral\", \"Against\", \"description\", \"date\"]]\n",
    "df_c.sort_values(by=\"date\").head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12978\n",
      "10382.400000000001\n",
      "2595.6000000000004\n",
      "10236\n",
      "2742\n"
     ]
    }
   ],
   "source": [
    "print(len(df_c))\n",
    "print(len(df_c)*0.8)\n",
    "print(len(df_c)*0.2)\n",
    "\n",
    "df_train = df_c[:10236]\n",
    "df_test = df_c[10236:]\n",
    "print(len(df_train))\n",
    "print(len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_vote(df):\n",
    "  \n",
    "  df['label'] = df.apply(lambda x: 1 if x['Neutral']<x['Against']>x['For'] else 0 if x['Neutral']<x['For']>x['Against'] else None, axis=1)\n",
    "\n",
    "  df.rename(columns={'description':'text'}, inplace=True)\n",
    "  df = df[['text', 'label']]\n",
    "  df = df.dropna()\n",
    "  df['label'] = df.apply(lambda x: int(x['label']), axis=1)\n",
    "\n",
    "  return df\n",
    "\n",
    "## Note \"Against\" = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\COBOD\\AppData\\Local\\Temp/ipykernel_12036/479257593.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['label'] = df.apply(lambda x: 1 if x['Neutral']<x['Against']>x['For'] else 0 if x['Neutral']<x['For']>x['Against'] else None, axis=1)\n",
      "c:\\Users\\COBOD\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:5039: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Beslutningsforslaget pålægger regeringen at la...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Folketinget opfordrer til fastholdelse af den ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  label\n",
       "49  Beslutningsforslaget pålægger regeringen at la...      1\n",
       "49  Folketinget opfordrer til fastholdelse af den ...      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = preprocess_vote(df_train)\n",
    "df_test = preprocess_vote(df_test)\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__'],\n",
       "        num_rows: 5802\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__'],\n",
       "        num_rows: 1560\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = Dataset.from_pandas(df_train, preserve_index=True)\n",
    "test_set = Dataset.from_pandas(df_test, preserve_index=True)\n",
    "dataset = DatasetDict({'train':train_set,\n",
    "                        'test':test_set})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Models\n",
    "klimaBERT = \"/klimaBERTe4_v2.1\"\n",
    "checkpoint = klimaBERT\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.22ba/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.88ba/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize(batch):\n",
    "    tokenized_batch = tokenizer(batch['text'], padding=True, truncation=True, max_length=512)\n",
    "    return tokenized_batch\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize, batched=True)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['labels',\n",
       "  '__index_level_0__',\n",
       "  'input_ids',\n",
       "  'token_type_ids',\n",
       "  'attention_mask'],\n",
       " 'test': ['labels',\n",
       "  '__index_level_0__',\n",
       "  'input_ids',\n",
       "  'token_type_ids',\n",
       "  'attention_mask']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Steps for processing data\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
    "\n",
    "## Rename label column to labels, if not already done\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets.column_names\n",
    "## Our model needs columns that it already knows (the 4 below, NOT any custom columns like \"text\"):\n",
    "#['labels', 'input_ids', 'token_type_ids', 'attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "from datasets import load_metric\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    roc_auc = roc_auc_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'roc_auc_score': roc_auc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "training_args = TrainingArguments(\"test-trainer\", evaluation_strategy=\"epoch\", per_device_train_batch_size=2, seed=2022, save_strategy=\"no\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2) #Change num  of labels if needed\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Set to use GPU\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "c:\\Users\\COBOD\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 5802\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8703\n",
      "  0%|          | 11/8703 [00:09<1:37:42,  1.48it/s]"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fc9de61b87691b5c2df4faa10d03c8011b5237e1331d96144d761a181cf79b3d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
