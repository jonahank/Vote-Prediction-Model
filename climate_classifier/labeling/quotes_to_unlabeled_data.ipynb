{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Quotes into Labeled Data for Binary Classification Finetuning (climate/non-climate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data\n",
    "\n",
    "Loading and converting the Gigawords and converting the parliament data into Pandas.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration DDSC--partial-danish-gigaword-no-twitter-c4bf5dfabf58d25e\n",
      "Reusing dataset parquet (/home/gugy/.cache/huggingface/datasets/parquet/DDSC--partial-danish-gigaword-no-twitter-c4bf5dfabf58d25e/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f24ea103674f1e817bdc5ce043d6c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/202 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"DDSC/partial-danish-gigaword-no-twitter\", split='train[0%:30%]')\n",
    "ds_ft = dataset.filter(lambda row: row['source']==('ft'))\n",
    "df_ft = ds_ft.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Regular Expressions to find the climate related material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r'((K|k)lima(forandringer)(ne)?|global(e)? opvarmning|(K|k)limakrise(n)|klimabelastende?|CO 2|CO2|CO_2|Co_2|CO2|Kuldioxid|drivhusgas(udledning(en)?)?|kulstofsudledningen|grøn(ne)? omstilling|CO 2-reduction|CO 2-neutral|Paris-aftalen|COP\\d{1,2}|CO 2-afgift|CO 2-skat)',\n",
       "re.UNICODE)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "#Some Danish climate-related regex:\n",
    "#klima = '(K|k)limaet)'\n",
    "klima_forandringer = '(K|k)lima(forandringer)(ne)?|global(e)? opvarmning|(K|k)limakrise(n)|klimabelastende?'\n",
    "co2 = 'CO 2|CO2|CO_2|Co_2|CO2|Kuldioxid|drivhusgas(udledning(en)?)?|kulstofsudledningen'\n",
    "målsætning = 'grøn(ne)? omstilling|CO 2-reduction|CO 2-neutral'\n",
    "politik = 'Paris-aftalen|COP\\d{1,2}|CO 2-afgift|CO 2-skat'\n",
    "løsninger = 'klimaløsning|CO 2-nedsættende'\n",
    "\n",
    "complete_klima_regex = re.compile(\"(%s|%s|%s|%s)\" % (klima_forandringer, co2, målsætning, politik))\n",
    "\n",
    "complete_klima_regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"Vi har fundet flere CO 2-kvoter her end vi havde regnet med. Det her er et klart tegn på Klimaforandringernes virkning.\\\n",
    "        Klimaforandringerne. forandringerne har været slemme. Men det grønne omstilling kan hjælpe os på vej. grøn omstilling \\\n",
    "        er vejen frem from at få nedsat CO  2-udledningen. CO 2-afgiften er slem\"\n",
    "        \n",
    "found = re.findall(complete_klima_regex, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_docs = []\n",
    "\n",
    "climate_quotes = {'text': [],\n",
    "      'speaker_id': [],\n",
    "      'doc_id': [],\n",
    "      'year': [],\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft_20171M38\n",
      "ft_20181M65\n",
      "ft_20161M3\n",
      "ft_20101M59\n",
      "ft_20191M32\n",
      "ft_20201M3\n",
      "ft_20181M92\n",
      "ft_20151M53\n",
      "ft_20181M3\n",
      "ft_20091M61\n",
      "ft_20191M50\n",
      "ft_20191M3\n",
      "ft_20131M97\n",
      "ft_20171M104\n",
      "ft_20191M146\n",
      "ft_20161M101\n",
      "ft_20191M8\n",
      "ft_20201M66\n",
      "ft_20091M49\n",
      "ft_20161M14\n",
      "ft_20191M110\n",
      "ft_20161M48\n",
      "ft_20131M69\n",
      "ft_20181M39\n",
      "ft_20191M64\n",
      "ft_20171M3\n",
      "ft_20201M78\n",
      "ft_20161M6\n",
      "ft_20091M93\n",
      "ft_20161M81\n",
      "ft_20201M52\n",
      "ft_20161M24\n",
      "ft_20101M45\n",
      "ft_20131M95\n",
      "ft_20191M134\n",
      "ft_20161M95\n",
      "ft_20191M39\n",
      "ft_20151M26\n",
      "ft_20101M94\n",
      "ft_20161M112\n",
      "ft_20121M97\n",
      "ft_20201M21\n",
      "ft_20191M128\n",
      "ft_20151M33\n",
      "ft_20171M48\n",
      "ft_20201M41\n",
      "ft_20191M44\n",
      "ft_20201M42\n",
      "ft_20201M79\n",
      "ft_20171M108\n",
      "ft_20181M53\n",
      "ft_20181M81\n",
      "ft_20091M43\n",
      "ft_20151M3\n",
      "ft_20201M22\n",
      "ft_20151M93\n",
      "ft_20161M105\n",
      "ft_20131M41\n",
      "ft_20091M68\n",
      "ft_20141M47\n",
      "ft_20141M62\n",
      "ft_20141M16\n",
      "ft_20091M13\n",
      "ft_20191M57\n"
     ]
    }
   ],
   "source": [
    "for index, row in df_ft.iterrows():\n",
    "\n",
    "        if len(re.findall(complete_klima_regex, row.text)) > 50:\n",
    "            doc_id = row.doc_id\n",
    "            climate_docs.append(doc_id)\n",
    "            \n",
    "            quotes = row.text.split(\"\\n\")    \n",
    "            \n",
    "            for quote in quotes:\n",
    "                \n",
    "                if re.search(complete_klima_regex, quote):\n",
    "                    climate_quotes['text'].append(quote.split(\":\")[1].strip())\n",
    "                    climate_quotes['speaker_id'].append(quote.split(\":\")[0].strip())\n",
    "                    climate_quotes['doc_id'].append(doc_id)\n",
    "                    climate_quotes['year'].append(re.search(r'\\d{4}', doc_id)[0])\n",
    "            \n",
    "            print(doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jeg er i hvert fald utrolig glad for, at vi me...</td>\n",
       "      <td>TALER 96</td>\n",
       "      <td>ft_20171M38</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vi vil jo især gerne – ud over selvfølgelig he...</td>\n",
       "      <td>TALER 96</td>\n",
       "      <td>ft_20171M38</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Det kunne også være, at det er, fordi man tænk...</td>\n",
       "      <td>TALER 23</td>\n",
       "      <td>ft_20171M38</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vi tager det sådan set meget alvorligt, at vi ...</td>\n",
       "      <td>TALER 23</td>\n",
       "      <td>ft_20171M38</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Man kunne jo godt ønske sig, at man havde mere...</td>\n",
       "      <td>TALER 137</td>\n",
       "      <td>ft_20171M38</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>Det anerkender jeg simpelt hen ikke er måden, ...</td>\n",
       "      <td>TALER 515</td>\n",
       "      <td>ft_20191M57</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>Jeg ser mig lige omkring for at se, om der er ...</td>\n",
       "      <td>TALER 482</td>\n",
       "      <td>ft_20191M57</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>Jeg tror, vi skal være meget forsigtige som po...</td>\n",
       "      <td>TALER 482</td>\n",
       "      <td>ft_20191M57</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>Tak for det – ligefrem højtærede. Jeg er i øvr...</td>\n",
       "      <td>TALER 493</td>\n",
       "      <td>ft_20191M57</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>Ja, vi kommer til at inddrage hele regeringen ...</td>\n",
       "      <td>TALER 493</td>\n",
       "      <td>ft_20191M57</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2497 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text speaker_id  \\\n",
       "0     Jeg er i hvert fald utrolig glad for, at vi me...   TALER 96   \n",
       "1     Vi vil jo især gerne – ud over selvfølgelig he...   TALER 96   \n",
       "2     Det kunne også være, at det er, fordi man tænk...   TALER 23   \n",
       "3     Vi tager det sådan set meget alvorligt, at vi ...   TALER 23   \n",
       "4     Man kunne jo godt ønske sig, at man havde mere...  TALER 137   \n",
       "...                                                 ...        ...   \n",
       "2492  Det anerkender jeg simpelt hen ikke er måden, ...  TALER 515   \n",
       "2493  Jeg ser mig lige omkring for at se, om der er ...  TALER 482   \n",
       "2494  Jeg tror, vi skal være meget forsigtige som po...  TALER 482   \n",
       "2495  Tak for det – ligefrem højtærede. Jeg er i øvr...  TALER 493   \n",
       "2496  Ja, vi kommer til at inddrage hele regeringen ...  TALER 493   \n",
       "\n",
       "           doc_id  year  \n",
       "0     ft_20171M38  2017  \n",
       "1     ft_20171M38  2017  \n",
       "2     ft_20171M38  2017  \n",
       "3     ft_20171M38  2017  \n",
       "4     ft_20171M38  2017  \n",
       "...           ...   ...  \n",
       "2492  ft_20191M57  2019  \n",
       "2493  ft_20191M57  2019  \n",
       "2494  ft_20191M57  2019  \n",
       "2495  ft_20191M57  2019  \n",
       "2496  ft_20191M57  2019  \n",
       "\n",
       "[2497 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_quotes_climate_sample = pd.DataFrame(climate_quotes)\n",
    "\n",
    "len(full_quotes_climate_sample)\n",
    "\n",
    "full_quotes_climate_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#Using seed to ensure full reproducibilty of the data (42 for original run)\n",
    "random.seed(20)\n",
    "\n",
    "quotes_random = {'text': [],\n",
    "      'speaker_id': [],\n",
    "      'doc_id': [],\n",
    "      'year': [],\n",
    "       }\n",
    "\n",
    "min_characters = 100\n",
    "\n",
    "while len(quotes_random['text']) < 5000:\n",
    "    random_meeting = df_ft.iloc[random.randint(0,len(df_ft))]\n",
    "    text = random_meeting['text'].split(\"\\n\")\n",
    "    facilitator = re.search(\"TALER \\d+:\", text[0])\n",
    "    #print(facilitator[0])\n",
    "\n",
    "\n",
    "    quotes_per_doc = 30\n",
    "    c = 0\n",
    "    while c < quotes_per_doc:\n",
    "        quote = text[random.randint(0,len(text)-1)]\n",
    "        if (not facilitator[0] in quote) & (len(quote) > min_characters):\n",
    "            speaker_id, quote = quote.split(\": \", 1)[0:2]\n",
    "            doc_id = random_meeting['doc_id']\n",
    "            \n",
    "            quotes_random['text'].append(quote)\n",
    "            quotes_random['speaker_id'].append(speaker_id)\n",
    "            quotes_random['doc_id'].append(doc_id)\n",
    "            quotes_random['year'].append(re.search(r'\\d{4}', doc_id)[0])\n",
    "            \n",
    "            c += 1\n",
    "            # print(doc_id), print(speaker_id), print(text)\n",
    "            \n",
    "    print(len(quotes_random['speaker_id']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_quotes_sample = pd.DataFrame(quotes_random)\n",
    "\n",
    "random_quotes_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize \n",
    "\n",
    "def split_by_sentence(df, num_sents):\n",
    "\n",
    "    sentences = {'text': [],\n",
    "      'speaker_id': [],\n",
    "      'doc_id': [],\n",
    "      'year': [],\n",
    "       }\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        sent_per_quote = sent_tokenize(row['text'], \"danish\")\n",
    "        \n",
    "        for i in range(len(sent_per_quote)):\n",
    "          quote = \"\"\n",
    "          while i % num_sents != 0:\n",
    "            quote =+ sent_per_quote[i]+\" \"\n",
    "          \n",
    "          sentences['text'].append(quote)\n",
    "          sentences['speaker_id'].append(row.speaker_id)\n",
    "          sentences['doc_id'].append(row.doc_id)\n",
    "          sentences['year'].append(row.year)\n",
    "          \n",
    "        # for sent in sent_per_quote:\n",
    "        #   sentences['text'].append(sent)\n",
    "        #   sentences['speaker_id'].append(row.speaker_id)\n",
    "        #   sentences['doc_id'].append(row.doc_id)\n",
    "        #   sentences['year'].append(row.year)\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bad operand type for unary +: 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17390/1666876629.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_by_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_quotes_climate_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_17390/1468709788.py\u001b[0m in \u001b[0;36msplit_by_sentence\u001b[0;34m(df, num_sents)\u001b[0m\n\u001b[1;32m     15\u001b[0m           \u001b[0mquote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m           \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnum_sents\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mquote\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0msent_per_quote\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m           \u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquote\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m           \u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'speaker_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspeaker_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: bad operand type for unary +: 'str'"
     ]
    }
   ],
   "source": [
    "test = split_by_sentence(full_quotes_climate_sample, 3)\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "\n",
    "sent_breakdown = {'text': [],\n",
    "      'speaker_id': [],\n",
    "      'doc_id': [],\n",
    "      'year': [],\n",
    "       }\n",
    "\n",
    "#Change this to get a different quote sample (random vs. cliamte regexed)\n",
    "full_quotes = full_quotes_climate_sample\n",
    "\n",
    "for index, row in full_quotes.iterrows():\n",
    "    \n",
    "    full_stops = re.compile(\"\\.|\\?|\\!\")\n",
    "    sents = re.split(full_stops, row.text)\n",
    "    \n",
    "    number_of_sentences = 3\n",
    "    \n",
    "    previous_index = 0\n",
    "    for i in range(0,len(sents), number_of_sentences):\n",
    "        sent_breakdown['text'].append(\".\".join(sents[previous_index:i]).strip()+\".\")\n",
    "        sent_breakdown['speaker_id'].append(row.speaker_id)\n",
    "        sent_breakdown['doc_id'].append(row.doc_id)\n",
    "        sent_breakdown['year'].append(row.year)\n",
    "        \n",
    "        previous_index = i\n",
    "        if i + 2 >= len(sents):\n",
    "            sent_breakdown['text'][-1] += \".\".join(sents[i:-1])\n",
    "        elif i + 3 >= len(sents):\n",
    "            sent_breakdown['text'].append(\".\".join(sents[i:-1]).strip()+\".\")\n",
    "            sent_breakdown['speaker_id'].append(row.speaker_id)\n",
    "            sent_breakdown['doc_id'].append(row.doc_id)\n",
    "            sent_breakdown['year'].append(row.year)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "\n",
    "sent_breakdown = {'text': [],\n",
    "      'speaker_id': [],\n",
    "      'doc_id': [],\n",
    "      'year': [],\n",
    "       }\n",
    "\n",
    "#Change this to get a different quote sample (random vs. cliamte regexed)\n",
    "full_quotes = full_quotes_climate_sample\n",
    "\n",
    "for index, row in full_quotes.iterrows():\n",
    "   \n",
    "    sents =\n",
    "     \n",
    "    number_of_sentences = 3\n",
    "    \n",
    "    previous_index = 0\n",
    "    for i in range(0,len(sents), number_of_sentences):\n",
    "        sent_breakdown['text'].append(\".\".join(sents[previous_index:i]).strip()+\".\")\n",
    "        sent_breakdown['speaker_id'].append(row.speaker_id)\n",
    "        sent_breakdown['doc_id'].append(row.doc_id)\n",
    "        sent_breakdown['year'].append(row.year)\n",
    "        \n",
    "        previous_index = i\n",
    "        if i + 2 >= len(sents):\n",
    "            sent_breakdown['text'][-1] += \".\".join(sents[i:-1])\n",
    "        elif i + 3 >= len(sents):\n",
    "            sent_breakdown['text'].append(\".\".join(sents[i:-1]).strip()+\".\")\n",
    "            sent_breakdown['speaker_id'].append(row.speaker_id)\n",
    "            sent_breakdown['doc_id'].append(row.doc_id)\n",
    "            sent_breakdown['year'].append(row.year)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sent_breakdown['text'])\n",
    "\n",
    "len(sent_breakdown['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nej, det mener vi ikke. Men man bruger i dag, ...</td>\n",
       "      <td>TALER 179</td>\n",
       "      <td>ft_20191M3</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Målet for vedvarende energi er et mål, som oft...</td>\n",
       "      <td>TALER 75</td>\n",
       "      <td>ft_20101M45</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000 statslige arbejdspladser, som regeringen a...</td>\n",
       "      <td>TALER 153</td>\n",
       "      <td>ft_20161M112</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andre lande kigger til os og ser på, hvordan v...</td>\n",
       "      <td>TALER 73</td>\n",
       "      <td>ft_20121M97</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Regering planlægger derfor i 2015 at fortsætte...</td>\n",
       "      <td>TALER 540</td>\n",
       "      <td>ft_20141M47</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>Det er ikke noget problem at lave en meget amb...</td>\n",
       "      <td>TALER 73</td>\n",
       "      <td>ft_20091M43</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>Ser ordføreren ikke, at der er et problem i de...</td>\n",
       "      <td>TALER 483</td>\n",
       "      <td>ft_20191M32</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>Der er heller ikke i sig selv tiltag, som kan ...</td>\n",
       "      <td>TALER 317</td>\n",
       "      <td>ft_20191M3</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>I de tilfælde har man jo brugt pisken og færre...</td>\n",
       "      <td>TALER 437</td>\n",
       "      <td>ft_20151M26</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>Det tegner godt, tænkte jeg. At der så også bl...</td>\n",
       "      <td>TALER 75</td>\n",
       "      <td>ft_20101M45</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text speaker_id  \\\n",
       "0     Nej, det mener vi ikke. Men man bruger i dag, ...  TALER 179   \n",
       "1     Målet for vedvarende energi er et mål, som oft...   TALER 75   \n",
       "2     000 statslige arbejdspladser, som regeringen a...  TALER 153   \n",
       "3     Andre lande kigger til os og ser på, hvordan v...   TALER 73   \n",
       "4     Regering planlægger derfor i 2015 at fortsætte...  TALER 540   \n",
       "...                                                 ...        ...   \n",
       "7995  Det er ikke noget problem at lave en meget amb...   TALER 73   \n",
       "7996  Ser ordføreren ikke, at der er et problem i de...  TALER 483   \n",
       "7997  Der er heller ikke i sig selv tiltag, som kan ...  TALER 317   \n",
       "7998  I de tilfælde har man jo brugt pisken og færre...  TALER 437   \n",
       "7999  Det tegner godt, tænkte jeg. At der så også bl...   TALER 75   \n",
       "\n",
       "            doc_id  year  \n",
       "0       ft_20191M3  2019  \n",
       "1      ft_20101M45  2010  \n",
       "2     ft_20161M112  2016  \n",
       "3      ft_20121M97  2012  \n",
       "4      ft_20141M47  2014  \n",
       "...            ...   ...  \n",
       "7995   ft_20091M43  2009  \n",
       "7996   ft_20191M32  2019  \n",
       "7997    ft_20191M3  2019  \n",
       "7998   ft_20151M26  2015  \n",
       "7999   ft_20101M45  2010  \n",
       "\n",
       "[8000 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_sentence = pd.DataFrame(sent_breakdown)\n",
    "\n",
    "three_sentence = three_sentence[three_sentence['text'] != '.']\n",
    "three_sentence.reset_index().drop(columns='index')\n",
    "\n",
    "#added climate sample\n",
    "climate_sample2 = three_sentence.sample(n=8000, random_state=42)\n",
    "\n",
    "climate_sample2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "climate_sample2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_sample2.to_pickle(\"climate_sample_v2_270322.pkl\")\n",
    "\n",
    "#pd.to_pickle(three_sentence, \"3sentence_climate_regex_quotes\")\n",
    "\n",
    "#pd.to_pickle(three_sentence, \"3sentence_random_quotes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the two dataframes\n",
    "\n",
    "Then we merge the two dfs to create the final dataset that we intend to label and use for fine-tune our binary classifier algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = pd.read_pickle(\"3sentence_random_quotes\")\n",
    "climate = pd.read_pickle(\"3sentence_climate_regex_quotes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [climate[0:500], random[0:300]]\n",
    "\n",
    "climate_and_random = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_and_random = climate_and_random.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_and_random.sample(frac=1).reset_index(drop=True).to_csv(\"800_3sent_unlabeled.csv\", encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding more data --> Expanding the dataset for the training data of KlimaBERT\n",
    "\n",
    "Below some more positives are labeled. From our first approach we would get a larger sample of negatives. This adds 180 positives (climate related quotes to our sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2190\n",
      "Så hvis det er sådan, at De Konservative har lidt højere ambitioner end regeringen, så er vi i Enhedslisten meget åbne over for en god dialog om, hvordan det kan udmønte sig i konkret handling. Og hvis vi skulle komme frem til noget om, at vi skal yde en mere aktiv indsats i EU for at få flere lande til at gå foran, så synes jeg, det kunne være spændende. Ordføreren fremhævede jo selv, at godt nok var der lavet nogle aftaler om mål på 1,5 graders global opvarmning, men at det, der er meldt ind, jo er noget, der ender med, at det nok bliver sådan 4-5 grader.\n",
      "\n",
      "2191\n",
      "Og ved at Alternativet går med, kan der blive et flertal for det. Jeg vil da godt høre, om det ikke ville være mere rimeligt, at Dansk Folkeparti stemte for det her forslag, når nu ordføreren siger, at man sådan set er kommet frem til, at vi når målsætningen om 40 procent CO 2 -reduktion. Så er det vel ikke så farligt, selv om De Konservative er med.\n",
      "\n",
      "2192\n",
      "Til allersidst mener vi også, der er behov for, at man kigger på et mere moderne it- og radiosystem. Jeg er tidligere kommet med eksempler på, hvordan politiet nærmest må ligge nederst i bunken og bruge deres egne telefoner til at ringe efter forstærkning. Det synes jeg ikke er passende.\n",
      "\n",
      "2193\n",
      "Ved folketingsvalget i juni var det jo for en gangs skyld ikke spindoktorer og politikere, som satte dagsordenen. Det var forældres og bedsteforældres krav om flere voksne i børnehaverne, der fyldte, og det var klimabekymrede borgere og især mange unge, som gjorde den grønne omstilling til et hovedtema ved valget. Når man ser på finansloven for 2020, må man sige, at det er en rigtig god finanslov.\n",
      "\n",
      "2194\n",
      "På transportsektorområdet savner Radikale Venstre også initiativer for at bremse CO 2 -udledningen fra biltrafikken. Regeringen indgik en bred trafikaftale i 2009, hvor der var et klart løfte om at komme med forslag til grønne kørselsafgifter. Løftet var, at der ville blive fremsat de nødvendige forslag i 2009 og 2010.\n",
      "\n",
      "2195\n",
      "Lige som arbejdet skulle til at gå i gang, ønsker man at komme til majestæten. Jeg ved, at Dansk Folkeparti tiltror kongehuset mangt og meget. Jeg har prøvet tre af disse dronningerunder.\n",
      "\n",
      "2196\n",
      "Danmark skal igen være et grønt foregangsland – det var ligesom budskabet. Men siden da blev det sådan lidt så som så med den grønne forandring. Klimadiskussionerne på Christiansborg tøffede rundt i sådan et business as usual-gear, og det ambitiøse klimamål, som vi satte i fællesskab, så ikke ud til at blive fulgt op af ambitiøs klimahandling.\n",
      "\n",
      "2197\n",
      "Nu nævner herre Morten Messerschmidt gartnerierhvervet. Tænker man ikke også, at det i fremtiden er et konkurrenceparameter, når der skal eksporteres potteplanter, at de er produceret på en miljøvenlig måde. Tror herre Morten Messerschmidt ikke også, at store datacentre kigger til, at det er grøn energi i Danmark, når de vælger at placere sig i Danmark, selv om det er lidt dyrere end i andre lande. Det tror jeg da\n",
      "\n",
      "2198\n",
      "Vi får Europas tredjebilligste strøm, hvilket selvfølgelig er glædeligt for vores eksport, vores produktionsvirksomheder og alle andre, der bruger energi, men det er også en mulighed for at gøre de største grønne fremskridt i nyere tid, da lavere elpriser tilskynder til en klimavenlig omstilling. I regeringen vil vi gøre el til et mere konkurrencedygtigt alternativ til opvarmning, transport med videre Det er eksempler på, at regeringen sætter handling bag ordene med grøn realisme frem for en grøn symbolpolitik. Vi ønsker netop, at Danmarks styrkepositioner fastholdes, og vi ønsker, at de danske virksomheder kan konkurrere på et internationalt marked.\n",
      "\n",
      "2199\n",
      "Tak for spørgsmålet. For Danmarks vedkommende bliver der ikke tale om anvendelse af CCS. For Danmarks vedkommende bliver der i forhold til udfasning af kul tale om reel udfasning. Der er to værker tilbage – Nordjyllandsværket og Fynsværket og til dels også Esbjergværket – og regeringen er gået i dialog med de pågældende værker i forhold til at sikre, at der sker en udfasning, og jeg tror, det kommer til at ske i betydelig tidligere end 2030\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(2190,2200):\n",
    "    print(i)\n",
    "    print(climate_sample2['text'][i])\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_lst = [1, 3, 4, 5, 6, 15, 18, 20, 21, 23, 25, 28, 30, 33, 35, 37, 39, 41, 46, 47, 49, 50, 52, 53, 56, 61, 64, 71, 72, 73, 74, 75, 82, 84, 86, 87, 91, 92, 109, 110, 112, 113, 116, 132, 134, 135, 137, 138, 139,\n",
    "             140, 143, 144, 145, 151, 156, 159, 162, 171, 172, 185, 186, 203, 209, 201, 217, 219, 220, 227, 235, 236, 241, 264, 266, 285, 286, 287, 289, 303, 304, 306, 313, 314, 315, 316, 319, 320, 323, 325, 339, 351,\n",
    "             357, 360, 362, 363, 369, 371, 399, 403, 406, 410, 411, 413, 425, 429, 432, 434, 437, 439, 441, 443, 445, 446, 450, 451, 453, 459, 467, 467, 472, 473, 475, 481, 489, 494, 500, 503, 506, 507, 509, 522, 527,\n",
    "             532, 544, 551, 552, 555, 563, 580, 581, 582, 597, 606, 609, 610, 617, 621, 2040, 2047, 2049, 2052, 2056, 2059, 2064, 2065, 2066, 2067, 2074, 2077, 2079, 2083, 2085, 2089, 2093, 2094, 2095, 2096, 2097, 2100,\n",
    "             2102, 2103, 2122, 2123, 2123, 2126, 2133, 2135, 2137, 2139, 2151, 2172, 2189, 2196]\n",
    "\n",
    "len(index_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vi kan skabe vækst i den velfærd, der kommer os alle sammen til gode, i stedet for at sænke skatten for dem, der har mest i forvejen. Vi har alle muligheder for at skabe et samfund, der i højere grad er rigt på den måde, vi behandler hinanden på, rigt på de muligheder, vi giver til hinanden og til vores børn. Vi skal fordele ressourcerne mere retfærdigt og smartere, ikke mindst.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_sample2['text'][119]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gugy/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "for i in index_lst:\n",
    "    climate_sample2.at[i, 'label'] = 1\n",
    "\n",
    "climate_sample_positives = climate_sample2[climate_sample2.label == 1.0]\n",
    "climate_sample_positives['label'] =climate_sample_positives['label'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_sample_positives[['text', 'label']].to_pickle(\"180climate_related_270322.pkl\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9bad1740bcceba7f5d41b1e47c34c82cc29408cbde07ec110077765843dd0cc0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
