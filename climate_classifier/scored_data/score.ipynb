{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['speaker', 'politician', 'title', 'party', 'text', 'date'],\n",
       "    num_rows: 335170\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data\n",
    "df = pd.read_pickle(\"../../data_collection/meetings/ft_meetings_2012-2022_clean_v2.3.pkl\")\n",
    "df_part = df\n",
    "test_set = Dataset.from_pandas(df_part, preserve_index=False)\n",
    "\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>politician</th>\n",
       "      <th>title</th>\n",
       "      <th>party</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Statsministeren Helle Thorning-Schmidt</td>\n",
       "      <td>Helle Thorning-Schmidt</td>\n",
       "      <td>Statsministeren</td>\n",
       "      <td>(S)</td>\n",
       "      <td>(Talen er under udarbejdelse) (Talen er under ...</td>\n",
       "      <td>2012-10-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Statsministeren Helle Thorning-Schmidt</td>\n",
       "      <td>Helle Thorning-Schmidt</td>\n",
       "      <td>Statsministeren</td>\n",
       "      <td>(S)</td>\n",
       "      <td>000 døgninstitutioner, opholdssteder og plejef...</td>\n",
       "      <td>2012-10-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  speaker              politician  \\\n",
       "1  Statsministeren Helle Thorning-Schmidt  Helle Thorning-Schmidt   \n",
       "2  Statsministeren Helle Thorning-Schmidt  Helle Thorning-Schmidt   \n",
       "\n",
       "             title party                                               text  \\\n",
       "1  Statsministeren   (S)  (Talen er under udarbejdelse) (Talen er under ...   \n",
       "2  Statsministeren   (S)  000 døgninstitutioner, opholdssteder og plejef...   \n",
       "\n",
       "        date  \n",
       "1 2012-10-02  \n",
       "2 2012-10-02  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Didn't find file /klimaBERTe4_v2.1\\added_tokens.json. We won't load it.\n",
      "loading file /klimaBERTe4_v2.1\\vocab.txt\n",
      "loading file /klimaBERTe4_v2.1\\tokenizer.json\n",
      "loading file None\n",
      "loading file /klimaBERTe4_v2.1\\special_tokens_map.json\n",
      "loading file /klimaBERTe4_v2.1\\tokenizer_config.json\n",
      "loading configuration file /klimaBERTe4_v2.1\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/klimaBERTe4_v2.1\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file /klimaBERTe4_v2.1\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /klimaBERTe4_v2.1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "## Load (part1)\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from datasets import load_metric\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    metric = load_metric(\"glue\", \"mrpc\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "checkpoint = \"/klimaBERTe4_v2.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
    "\n",
    "## Load trainer API\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Set to use GPU\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 336/336 [02:09<00:00,  2.59ba/s]\n"
     ]
    }
   ],
   "source": [
    "## Load FT data and tokenize it\n",
    "def tokenize(batch):\n",
    "    tokenized_batch = tokenizer(batch['text'], padding=True, truncation=True, max_length=512)\n",
    "    return tokenized_batch\n",
    "\n",
    "dataset = test_set\n",
    "tokenized_datasets = dataset.map(tokenize, batched=True)\n",
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: speaker, date, title, text, party, politician. If speaker, date, title, text, party, politician are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 335170\n",
      "  Batch size = 8\n",
      "100%|██████████| 41897/41897 [8:08:26<00:00,  2.27it/s]  "
     ]
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 4.548115 , -3.5720406],\n",
       "       [ 4.5659766, -3.5668213],\n",
       "       [ 4.5911045, -3.52495  ],\n",
       "       ...,\n",
       "       [ 4.7219825, -3.7248368],\n",
       "       [ 4.7001395, -3.6855257],\n",
       "       [ 4.675691 , -3.712501 ]], dtype=float32), label_ids=None, metrics={'test_runtime': 29309.9375, 'test_samples_per_second': 11.435, 'test_steps_per_second': 1.429})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Predict on sub-set\n",
    "predictions2 = trainer.predict(tokenized_datasets)\n",
    "predictions2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "\n",
    "for (i,j) in predictions2[0]:\n",
    "  if i > j: label.append(\"non-climate\")\n",
    "  else: label.append(\"climate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_compare = pd.DataFrame()\n",
    "df_compare = dataset.to_pandas()\n",
    "df_compare[\"y_pred\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred:climate 17226\n",
      "y_pred:non-climate 317944\n",
      "all 335170\n"
     ]
    }
   ],
   "source": [
    "df_climate = df_compare[df_compare[\"y_pred\"]==\"climate\"].reset_index()\n",
    "df_non_climate = df_compare[df_compare[\"y_pred\"]==\"non-climate\"].reset_index()\n",
    "print(\"y_pred:climate\",len(df_climate.index))\n",
    "print(\"y_pred:non-climate\",len(df_non_climate.index))\n",
    "print(\"all\", len(df_compare))\n",
    "\n",
    "df_climate.to_pickle(\"ft_meetings_climate_all_2.3.pkl\")\n",
    "df_non_climate.to_pickle(\"ft_meetings_non_climate_all_2.3.pkl\")\n",
    "df_compare.to_pickle(\"ft_meetings_all_2.3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fc9de61b87691b5c2df4faa10d03c8011b5237e1331d96144d761a181cf79b3d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
